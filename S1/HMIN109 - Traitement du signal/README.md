# HMIN109 - Traitement du signal

## Sommaire [‚Ü∫](#sommaire-)

* [Informations](#informations-)
  + [Examens](#examens-)
  + [Ressources](#ressources-)

## Informations [‚Ü∫](#sommaire-)

### Examens [‚Ü∫](#sommaire-)

- Note final : 67% Exam + 33% TP

### Ressources [‚Ü∫](#sommaire-)

- [Cours](http://www.lirmm.fr/~wpuech/enseignement/master_informatique/index.html)
- [TPs](http://www.lirmm.fr/~strauss/MasterInfo/TravauxPratiquesHMIN109.html)

## I) LES R√âSEAUX

- Applications : telnet, ftp, nfs
- Ordinateurs  : PC, stations de travail, p√©riph√©riques, terminaux
- Coupleurs    : asynchrone, synchrone, ethernet
- Adaptateurs  : modem, transceiver
- Liens        : paire trosad√©e, c√¢ble coaxial, fibre optique, ondes hertziennes.
- Connexion et interconnection : noeuds, routeurs, commutateurs, r√©p√©teurs.
- Langages : signaux √©lectriques, bytes, trames, fonctions dans les applications.
- Normes et standards : 

**Buts**

- Echanges entre personnes
- Partage d√©quipements
- Terme r√©seau tr√®s vague

**Supports : des caract√®ristiques au choix**

- Co√ªt
- Bande passante

**Codage de l'information**

- Alphabet
- ASCII (1 lettre = 1 octet)
- Paquets
- 8 bits ou 7 bits + parit√© ou 4B/5B 
- Signaux sur le support
- Niveaux et changements de niveaux

### **Exemple : Bit de parit√©**
```
On r√©sonne sur les bits √† 0

0 1 2 3 4 5 6 7
0 0 1 1 0 1 0|1 (bit de parit√©)

Ici on compte les bits √† 0 et on ne rajoute pas de 0 sur le bit de parit√© pour avoir un nombre de 0 pair.
```
**Modes de transmission**

- Bits : singaux de support
- Bande de base : repr√©sentation directe des bits
- Analogique : modem et porteuse

**Synchronisation entre √©metteur et r√©cepteur**

- Synchrone : horloge transmise avec les donn√©es
- Asynchrone : devant chaque √©l√©ments de donn√©es on ajoute un groupe de bits pour l'√©chantillonnge

**Les erreurs**

l'information re√ßue doit √™tre identique √† l'information √©mise.
Le signale peut √™tre modifi√©, des bits ou octets perdus durant le transfert de l'information : erreurs
Il faut les d√©tecter et les corriger.

- Detection d'une modification
- l'√©metteur rajoute des bits, fonction des donn√©es qu'il transmet
- Le r√©cepteur recalcule la fonction et v√©rifie

- D√©tection d'une perte (paquet) : besoin de num√©rotation, ajout√©e par l'√©metteur et v√©rifi√©e par le r√©cepteur
- D√©tection d'un mauvais ordre d'arriv√©e : r√©seaux maill√©s

**Fen√™trage**

- Un Ack accus√© r√©ception de plusieurs √©l√©ments d'information.
- Primordial dans les transferts de fichiers

**Contr√¥le de flux**

- Flot d'arriv√©e trop rapide pour le r√©cepteur ou poru les noeuds interm√©diares
- Quand fen√™trage : r√©solu par l'√©metteur
- Asynchrone : XON - XOFF
- ICMP : Source Quench

**Mode connect√© (un paquet fait le train, les autres suivent)**

- En d√©but de chaque session : cr√©ation d'un chemin virtuel CV entre les deux protagonistes
- Chaque noeud r√©serve les ressources n√©cessaires √† la session
- Dans chaque √©l√©ment d'information : num√©ro du CV
- Fin de session : chaque noeud est averti
- Exemple : t√©l√©phone, X25, 

**Mode non connect√© (chaque paquet est un train qui trouve sont chemin)**

- Chaque √©l√©ment d'information (datagramme) qui circule contient l'adresse du destinataire et de l'√©metteur.
- Les noeuds (routeurs) dispatchent √† la vol√©e : il faut trouve le bon chemin rapidement (but du routage)

**Les couches**

- Chaque couche ajoute un ent√™te et un identificateur de la couche sup√©rieur

**Adressage et nommage**

- But : identifier un objet r√©seau
- Adrese li√©e √† la g√©ographie
- Nom li√© √† la fonction ou l'indetit√© (personne)
- Probl√®me : unicit√© et gestion

## II) CONCEPTS DES T√âL√âCOMMUNCATIONS

**Forme**

- texte
- musique
- images fixes

**Codage**

- Adaptation au canal de communication
- Capteurs et transducteurs

### Codage en bande de base

- Binaire
```
	1 0 1 1 0 0 0 0 0 1 0 0 0 0 0
	- _ - - _ _ _ _ _ - _ _ _ _ _
```

- Bipolaire (sequences de O <= n+1)
```
	1 0 1 1 0 0 0 0 0 1 0 0 0 0 0
	- _   - _ _ _ _ _   _ _ _ _ _
		-             -
```

- HDB3n (Haute densit√© bourrage) 
```
	1 0 1 1 0 0 0 0 0 1 0 0 0 0 0
	- _   -   _ _ - _   _ _ _   _
		-   -         -       -
```

**T√©l√©informatique**

- Echantillonage: Shannon Fe >= 2 Fmax
- Quantification/codage: Si D est la dynamique du signal: n >= log2 D
- Debit du signal num√©ris√©: C >= n * Fe (bits/s)

### S√©curisation de la transmission 

- Taux d'erreur binaire (TEB) = (nb bits erron√©s) / (nb bits transmis)
- Soit n le nombre de bits du message, la probabilit√© de transmission sans erreur P = (1 - TEB)^n

**Cl√©s de contr√¥le**

- Bit de parit√© : VRC, efficacit√© 50 - 60%
- Caract√®re de parit√© : LRC, efficacit√© 95%
- Combinaison VRC/LRC
- Envoi de la m√™me trame en plusieurs exemplaires
- Cl√©s de contr√¥le de 2 √† 4 octets, CRC (Cyclic Redundancy Check), efficacit√© 100%

### Eficacit√©

- Taux de transfert des informations, TTI = (nb de bits utiles) / (dur√©e de transmission)
- Rendement du support = TTI / D√©bit nominal du support

### Exemple : Taux de transfert des informations

```
Message 1000 caract√®re aCSII avec 1 bit VRC/caract√®re, liaison 9600 bits/s, TEB = 10^-4
P = (1 - 10^-4)^8*1000 = 44%

Templs de transmission sans tenir compte des erreurs t = 8000/9600 = 0.83s
TTI = 7000/0.83 = 8403 bits/s

Temps de transmission avec erreurs : tc = t/P = 0.83/0.44 = 1.89s
TTIe = 7000/1.89 = 3696  bits/s

Rendement = 3696/9600 = 38%
```

**Compression**

- Image, JPEG, MPEG1, MPEG2
- Texte, codage de la longueur de ligne, codage de huffman

### Exemple : Codage par plage RLE, RLC (Run Length Encoding/Coding)

```
223 223 223 214 214 214 214 223 223 223 217 214 214 214 = 14 * 8 bits = 112 bits
  {3,223}       {4,214}       {3,223} {1,217} {3,214}   = 5*(8+2) = 50 bits

Est interressant quand il y a de la redondance d'affiler
```

**Codage de Huffman**

- Codage √† longueur variable
- Symboles tr√®s frequent -> codes courts
- Symboles rares -> codes longs
- Un code ne doit jamais √™tre le d√©but d'un autre code

1. Trier les symboles par probabilit√© d√©croissante
2. Regrouper les 2 symboles qui ont les probabilit√©s les plus faibles
3. Remplacer ces symboles par un symbole : somme des probabilit√© des caract√®res
4. Tant que tout n'est pas regroup√© : rentour en 2
5. En partant du bas et remontant jusqu'au bout
- √† gauche : ajouer un 0
- √† droite : ajouter un 1

## III) Le r√©seau de t√©l√©communication

**Trafic t√©l√©phonique**

- Soit N(t) le nombre de circuits occup√©s √† l'instant t, le volume de trafic pendant un temps T: V(t) = integrale[0,T] N(t) dt en secondes
- Intensit√© du trafic (en erlang ou %): I(T) = 1/T V(t)

```
1 erlang = 1 E -> 1 ligne pendant 1 heure
               -> 2 ligne pendant 1/2 heure
```

Circuit:
```
 ü¢ë
1‚îÉ‚îÅ‚îÅ‚îÅ ‚îÅ ‚îÅ‚îÅ‚îÅ
2‚îÉ ‚îÅ‚îÅ‚îÅ ‚îÅ‚îÅ  ‚îÅ‚îÅ‚îÅ
3‚îÉ‚îÅ‚îÅ‚îÅ ‚îÅ‚îÅ   ‚îÅ‚îÅ
4‚îÉ ‚îÅ‚îÅ‚îÅ  ‚îÅ‚îÅ‚îÅ
5‚îÉ   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
 ‚îó‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅü¢í

1) 5 circuits : inutile
2) 4 circuits : les 12 communication sont √©tablies
3) 3 circuits : 2 sessions sont perdues
```

Compromis : 3 param√®tres

- Trafic
- Capacit√© du faisceau : n
- Probabilit√© de perte

Probabilit√© de pertes:
```
p = (E^n / n!) / (somme[h = 0, n] E^h / h!)
```

Ex: 2 faisceaux de 10 circuits
-> trafic de 5 erlangs
-> p = 2%

Rendement = 0,5 E/circuit

Regroupe les √© faisceaux
-> 1 faisceau de 20 circuits
-> p = 2%
-> trafic de 13 Erlangs

Rendement = 0.65 E/circuit

## IV) R√©seau

**Exemple**

D√©bit de 9600 bits/s message de 300 octets 3 liaisons : L = 3
liaison = 0.25s
transit = 0.75s

message en 3 paquets
T un paquet-liaison = 0.83s
100 octets
Transit = 0.417s

## Traitement Lin√©aire Des Signaux

### I. Signal

**1. Qu'est-ce ?**

- Transfert d'information
- Support :
	- Courant electrique
	- Champs electro-magnetiques
	- Pression acoustique
	- Variation du Support

**D√©finition** : Une information qui est cod√© sous la forme d'une variation d'une grandeur intensive (mesurable) en fonction d'une grandeur extensive (que l'on peut indexer).

**2. Signaux √©l√©mentaires**

- **Continu** : un signal pour lequel on poss√®de toutes les donn√©es (physique).
- **Analogique** : La seule diff√©rence avec le signal continu est la mani√®re dont on traite ce signal.
- **Echantillon√©** : Transformation des signaux en valeures enti√®res (signaux numeriques).

**3. Mod√®les math√©matiques**

(schema)

**4. Fourier**

![equation][1]
[1]: https://latex.codecogs.com/svg.latex?\Large&space;s(t)=\sum_{i}^nAi.sin(w_it+q_i)

![equation][2]
[2]: https://latex.codecogs.com/svg.latex?\Large&space;\int&space;s(t).sin(w_0t)dt=B\int&space;sin^2(w_0t)dt

![equation][3]
[3]: https://latex.codecogs.com/svg.latex?\Large&space;\int_0^{\infty}s(t)e^{-iwt}dt

**5. Transformation de Fourier**

- **Lin√©arit√©** : TF { f(t) + g(t) } = TF { f(t)} + TF{g(t) }
- Soit Œª ‚àà ‚Ñù : TF { Œª.f(t) } = Œª.TF { f(t) }

### II. Syst√®mes Lin√©aires

**1. Qu'est ce ?**

- Le systeme est lineaire si :
	- e‚ÇÅ(t) ‚Üí s‚ÇÅ(t)
	- e‚ÇÇ(t) ‚Üí s‚ÇÇ(t)
	- e‚ÇÉ(t) = e‚ÇÅ(t) + e‚ÇÇ(t) ‚Üí s‚ÇÉ(t) = s‚ÇÅ(t) + s‚ÇÇ(t)

**2. Syst√®mes**

![equation][4]
[4]: https://latex.codecogs.com/svg.latex?\Large&space;\sum_{i=1}^{n}i^3=\frac{n(n+1)}{2}^2

